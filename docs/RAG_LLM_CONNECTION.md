# ğŸ”— RAGì™€ LLMì˜ ì—°ê²° ì›ë¦¬

Vector ê²€ìƒ‰ìœ¼ë¡œ ì°¾ì€ ë¬¸ì„œê°€ ì–´ë–»ê²Œ LLMì— ì „ë‹¬ë˜ëŠ”ì§€ ìì„¸íˆ ì„¤ëª…í•©ë‹ˆë‹¤.

---

## ğŸ¯ í•µì‹¬ ê°œë…

```
RAG = Retrieval-Augmented Generation
       ê²€ìƒ‰ìœ¼ë¡œ ë³´ê°•ëœ    ìƒì„±

= Vector ê²€ìƒ‰ + LLM ìƒì„±
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”€â”€â”€â”€â”€â”€â”€â”€
  ê´€ë ¨ ë¬¸ì„œ ì°¾ê¸°   ë‹µë³€ ìƒì„±
```

---

## ğŸ”„ ì „ì²´ íë¦„ë„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RAG ì‹œìŠ¤í…œ ì „ì²´ íë¦„                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ì‚¬ìš©ì ì§ˆë¬¸: "Pythonìœ¼ë¡œ ë¦¬ìŠ¤íŠ¸ ì •ë ¬í•˜ëŠ” ë°©ë²•?"
    â”‚
    â†“
â”Œâ”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1ï¸âƒ£  RETRIEVAL (ê²€ìƒ‰) - ChromaDB                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â”‚ [ì§ˆë¬¸ì„ ë²¡í„°ë¡œ ë³€í™˜]
    â”‚ "Python ë¦¬ìŠ¤íŠ¸ ì •ë ¬" â†’ [0.1, 0.5, 0.8, ...]
    â”‚
    â†“
    â”‚ [ìœ ì‚¬ë„ ê²€ìƒ‰]
    â”‚ ChromaDBì—ì„œ ê´€ë ¨ ë¬¸ì„œ ì°¾ê¸°
    â”‚
    â†“
    â”‚ [ê²€ìƒ‰ ê²°ê³¼]
    â”‚ âœ… ë¬¸ì„œ1: "Python sort() ë©”ì„œë“œ" (ìœ ì‚¬ë„ 0.95)
    â”‚ âœ… ë¬¸ì„œ2: "sorted() í•¨ìˆ˜ ì‚¬ìš©ë²•" (ìœ ì‚¬ë„ 0.92)
    â”‚ âœ… ë¬¸ì„œ3: "ë¦¬ìŠ¤íŠ¸ ì •ë ¬ ì˜ˆì œ" (ìœ ì‚¬ë„ 0.88)
    â”‚
    â†“
â”Œâ”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2ï¸âƒ£  AUGMENTATION (ë³´ê°•) - í”„ë¡¬í”„íŠ¸ êµ¬ì„±                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â”‚ [ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±]
    â”‚ ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ë¡œ í•©ì¹¨:
    â”‚
    â”‚ """
    â”‚ [ë¬¸ì„œ1] Pythonì˜ sort() ë©”ì„œë“œëŠ” ë¦¬ìŠ¤íŠ¸ë¥¼ 
    â”‚        ì œìë¦¬ì—ì„œ ì •ë ¬í•©ë‹ˆë‹¤...
    â”‚ 
    â”‚ [ë¬¸ì„œ2] sorted() í•¨ìˆ˜ëŠ” ìƒˆë¡œìš´ ì •ë ¬ëœ 
    â”‚        ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤...
    â”‚ 
    â”‚ [ë¬¸ì„œ3] ì˜ˆì œ ì½”ë“œ:
    â”‚        numbers = [3, 1, 4, 1, 5]
    â”‚        numbers.sort()
    â”‚ """
    â”‚
    â†“
    â”‚ [í”„ë¡¬í”„íŠ¸ ìƒì„±]
    â”‚ ì§ˆë¬¸ + ì»¨í…ìŠ¤íŠ¸ë¥¼ LLMìš© í”„ë¡¬í”„íŠ¸ë¡œ ë§Œë“¦:
    â”‚
    â”‚ """
    â”‚ ë‹¤ìŒ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”:
    â”‚
    â”‚ [ì°¸ê³  ë¬¸ì„œ]
    â”‚ [ë¬¸ì„œ1] Pythonì˜ sort()...
    â”‚ [ë¬¸ì„œ2] sorted() í•¨ìˆ˜ëŠ”...
    â”‚ [ë¬¸ì„œ3] ì˜ˆì œ ì½”ë“œ...
    â”‚
    â”‚ [ì§ˆë¬¸]
    â”‚ Pythonìœ¼ë¡œ ë¦¬ìŠ¤íŠ¸ ì •ë ¬í•˜ëŠ” ë°©ë²•?
    â”‚ """
    â”‚
    â†“
â”Œâ”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3ï¸âƒ£  GENERATION (ìƒì„±) - LLM                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â”‚ [LLM í˜¸ì¶œ]
    â”‚ OpenAI API, Claude API, Ollama ë“±ì— ì „ë‹¬
    â”‚
    â†“
    â”‚ [LLMì´ í”„ë¡¬í”„íŠ¸ ì½ìŒ]
    â”‚ - ì°¸ê³  ë¬¸ì„œ ì´í•´
    â”‚ - ì§ˆë¬¸ ì´í•´
    â”‚ - ë¬¸ì„œ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ ìƒì„±
    â”‚
    â†“
    â”‚ [LLM ë‹µë³€]
    â”‚ "Pythonì—ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì •ë ¬í•˜ëŠ” ë°©ë²•ì€ 2ê°€ì§€ì…ë‹ˆë‹¤:
    â”‚  
    â”‚  1. sort() ë©”ì„œë“œ: ì›ë³¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ì§ì ‘ ì •ë ¬
    â”‚     numbers = [3, 1, 4]
    â”‚     numbers.sort()
    â”‚  
    â”‚  2. sorted() í•¨ìˆ˜: ìƒˆ ì •ë ¬ëœ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
    â”‚     new_numbers = sorted([3, 1, 4])
    â”‚  
    â”‚  (ì°¸ê³ : ë¬¸ì„œ1, ë¬¸ì„œ2)"
    â”‚
    â†“
ì‚¬ìš©ìì—ê²Œ ë‹µë³€ ì „ë‹¬
```

---

## ğŸ’» ì‹¤ì œ ì½”ë“œë¡œ ë³´ëŠ” ì—°ê²°

### ì „ì²´ ê³¼ì •

```python
from rag.vector_store import ChromaVectorStore
from embedding_service import EmbeddingService
from llm_service import LLMService  # OpenAI, Claude, Ollama ë“±

def rag_answer(user_question: str) -> str:
    """RAG ì‹œìŠ¤í…œìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€"""
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # STEP 1: RETRIEVAL (ê²€ìƒ‰)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    # 1-1. ì´ˆê¸°í™”
    store = ChromaVectorStore("./chroma-data")
    embedder = EmbeddingService()
    
    # 1-2. ì§ˆë¬¸ì„ ë²¡í„°ë¡œ ë³€í™˜
    question_vector = embedder.encode(user_question)
    # "Python ë¦¬ìŠ¤íŠ¸ ì •ë ¬" â†’ [0.1, 0.5, 0.8, ..., 0.3]
    
    # 1-3. ChromaDBì—ì„œ ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰
    search_results = store.search_vectors(
        collection_name="tech_docs",
        query_embedding=question_vector,
        limit=3  # ìƒìœ„ 3ê°œ ë¬¸ì„œ
    )
    
    # ê²€ìƒ‰ ê²°ê³¼:
    # [
    #   {"content": "Python sort() ë©”ì„œë“œ...", "similarity": 0.95},
    #   {"content": "sorted() í•¨ìˆ˜...", "similarity": 0.92},
    #   {"content": "ì •ë ¬ ì˜ˆì œ...", "similarity": 0.88}
    # ]
    
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # STEP 2: AUGMENTATION (ë³´ê°•) - í•µì‹¬ ì—°ê²° ë¶€ë¶„!
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    # 2-1. ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ í•˜ë‚˜ì˜ ì»¨í…ìŠ¤íŠ¸ë¡œ í•©ì¹˜ê¸°
    context_parts = []
    for i, result in enumerate(search_results, 1):
        doc_text = result['content']
        context_parts.append(f"[ë¬¸ì„œ{i}] {doc_text}")
    
    context = "\n\n".join(context_parts)
    
    # context ë‚´ìš©:
    # """
    # [ë¬¸ì„œ1] Pythonì˜ sort() ë©”ì„œë“œëŠ”...
    # 
    # [ë¬¸ì„œ2] sorted() í•¨ìˆ˜ëŠ”...
    # 
    # [ë¬¸ì„œ3] ì •ë ¬ ì˜ˆì œ...
    # """
    
    
    # 2-2. LLMìš© í”„ë¡¬í”„íŠ¸ ìƒì„± â† ì—¬ê¸°ê°€ í•µì‹¬ ì—°ê²°!
    prompt = f"""ë‹¹ì‹ ì€ ì¹œì ˆí•œ í”„ë¡œê·¸ë˜ë° ë„ìš°ë¯¸ì…ë‹ˆë‹¤.
ë‹¤ìŒ ì°¸ê³  ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.

[ì°¸ê³  ë¬¸ì„œ]
{context}

[ì‚¬ìš©ì ì§ˆë¬¸]
{user_question}

[ë‹µë³€ ê·œì¹™]
1. ì°¸ê³  ë¬¸ì„œì˜ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”
2. ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”
3. ì½”ë“œ ì˜ˆì œê°€ ìˆìœ¼ë©´ í¬í•¨í•˜ì„¸ìš”
4. ì¹œì ˆí•˜ê³  ëª…í™•í•˜ê²Œ ì„¤ëª…í•˜ì„¸ìš”

ë‹µë³€:"""
    
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # STEP 3: GENERATION (ìƒì„±)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    # 3-1. LLMì— í”„ë¡¬í”„íŠ¸ ì „ë‹¬
    llm = LLMService()
    answer = llm.generate(prompt)
    
    # LLMì´ ë°›ëŠ” ë‚´ìš©:
    # - ì°¸ê³  ë¬¸ì„œ 3ê°œ (ê²€ìƒ‰ëœ ë‚´ìš©)
    # - ì‚¬ìš©ì ì§ˆë¬¸
    # - ë‹µë³€ ê·œì¹™
    
    # LLMì´ í•˜ëŠ” ì¼:
    # - ë¬¸ì„œ ì½ê³  ì´í•´
    # - ì§ˆë¬¸ì— ë§ëŠ” ë‹µë³€ ìƒì„±
    # - ë¬¸ì„œ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•˜ê²Œ ë‹µë³€
    
    
    # 3-2. ë‹µë³€ ë°˜í™˜
    return answer

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ì‚¬ìš© ì˜ˆì‹œ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

question = "Pythonìœ¼ë¡œ ë¦¬ìŠ¤íŠ¸ ì •ë ¬í•˜ëŠ” ë°©ë²•?"
answer = rag_answer(question)

print(answer)
# ì¶œë ¥:
# """
# Pythonì—ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì •ë ¬í•˜ëŠ” ë°©ë²•ì€ 2ê°€ì§€ì…ë‹ˆë‹¤:
# 
# 1. sort() ë©”ì„œë“œ (ì œìë¦¬ ì •ë ¬)
#    numbers = [3, 1, 4, 1, 5]
#    numbers.sort()
#    print(numbers)  # [1, 1, 3, 4, 5]
# 
# 2. sorted() í•¨ìˆ˜ (ìƒˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜)
#    numbers = [3, 1, 4, 1, 5]
#    sorted_numbers = sorted(numbers)
#    print(sorted_numbers)  # [1, 1, 3, 4, 5]
# 
# ì£¼ìš” ì°¨ì´ì : sort()ëŠ” ì›ë³¸ì„ ë³€ê²½í•˜ê³ , sorted()ëŠ” 
# ìƒˆ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
# """
```

---

## ğŸ” ìƒì„¸ ë¶„ì„: ì—°ê²° ê³¼ì •

### 1ï¸âƒ£ ê²€ìƒ‰ ê²°ê³¼ â†’ ì»¨í…ìŠ¤íŠ¸ ë³€í™˜

```python
# ChromaDB ê²€ìƒ‰ ê²°ê³¼ (ë¦¬ìŠ¤íŠ¸)
search_results = [
    {
        "id": "doc_001",
        "content": "Pythonì˜ sort() ë©”ì„œë“œëŠ” ë¦¬ìŠ¤íŠ¸ë¥¼ ì œìë¦¬ì—ì„œ ì •ë ¬í•©ë‹ˆë‹¤.",
        "similarity_score": 0.95,
        "metadata": {"title": "sort() ì‚¬ìš©ë²•"}
    },
    {
        "id": "doc_002", 
        "content": "sorted() í•¨ìˆ˜ëŠ” ìƒˆë¡œìš´ ì •ë ¬ëœ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.",
        "similarity_score": 0.92,
        "metadata": {"title": "sorted() í•¨ìˆ˜"}
    }
]

# â†“ ë³€í™˜ â†“

# LLMìš© ì»¨í…ìŠ¤íŠ¸ (ë¬¸ìì—´)
context = """
[ë¬¸ì„œ1: sort() ì‚¬ìš©ë²•]
Pythonì˜ sort() ë©”ì„œë“œëŠ” ë¦¬ìŠ¤íŠ¸ë¥¼ ì œìë¦¬ì—ì„œ ì •ë ¬í•©ë‹ˆë‹¤.

[ë¬¸ì„œ2: sorted() í•¨ìˆ˜]
sorted() í•¨ìˆ˜ëŠ” ìƒˆë¡œìš´ ì •ë ¬ëœ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
"""
```

### 2ï¸âƒ£ ì»¨í…ìŠ¤íŠ¸ + ì§ˆë¬¸ â†’ í”„ë¡¬í”„íŠ¸

```python
# ì»¨í…ìŠ¤íŠ¸ (ê²€ìƒ‰ëœ ë¬¸ì„œ)
context = "..."

# ì‚¬ìš©ì ì§ˆë¬¸
question = "Pythonìœ¼ë¡œ ë¦¬ìŠ¤íŠ¸ ì •ë ¬í•˜ëŠ” ë°©ë²•?"

# â†“ ê²°í•© â†“

# LLM í”„ë¡¬í”„íŠ¸ (ìµœì¢…)
prompt = f"""
ë‹¹ì‹ ì€ í”„ë¡œê·¸ë˜ë° ë„ìš°ë¯¸ì…ë‹ˆë‹¤.
ë‹¤ìŒ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”:

{context}

ì§ˆë¬¸: {question}
"""

# ì´ promptë¥¼ LLM APIì— ì „ë‹¬!
```

### 3ï¸âƒ£ í”„ë¡¬í”„íŠ¸ â†’ LLM â†’ ë‹µë³€

```python
# OpenAI API ì˜ˆì‹œ
import openai

response = openai.ChatCompletion.create(
    model="gpt-4",
    messages=[
        {
            "role": "system",
            "content": "ë‹¹ì‹ ì€ í”„ë¡œê·¸ë˜ë° ë„ìš°ë¯¸ì…ë‹ˆë‹¤."
        },
        {
            "role": "user",
            "content": prompt  # â† ì—¬ê¸°ì— ì»¨í…ìŠ¤íŠ¸ + ì§ˆë¬¸!
        }
    ]
)

answer = response.choices[0].message.content
```

---

## ğŸ¨ í”„ë¡¬í”„íŠ¸ êµ¬ì„± ë°©ì‹ ë¹„êµ

### ë°©ì‹ A: ê°„ë‹¨í•œ ë²„ì „

```python
def simple_rag_prompt(context: str, question: str) -> str:
    return f"""
ì°¸ê³  ë¬¸ì„œ:
{context}

ì§ˆë¬¸: {question}

ë‹µë³€:"""
```

### ë°©ì‹ B: ìƒì„¸í•œ ë²„ì „ (ê¶Œì¥)

```python
def detailed_rag_prompt(context: str, question: str) -> str:
    return f"""ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ ê¸°ìˆ  ì§€ì› AIì…ë‹ˆë‹¤.

[ì—­í• ]
- ì‚¬ìš©ìì˜ ê¸°ìˆ ì  ì§ˆë¬¸ì— ì •í™•íˆ ë‹µë³€í•©ë‹ˆë‹¤
- ì œê³µëœ ë¬¸ì„œì˜ ë‚´ìš©ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤
- ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ "ë¬¸ì„œì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µí•©ë‹ˆë‹¤

[ì°¸ê³  ë¬¸ì„œ]
{context}

[ì‚¬ìš©ì ì§ˆë¬¸]
{question}

[ë‹µë³€ í˜•ì‹]
1. í•µì‹¬ ë‹µë³€ì„ ë¨¼ì € ì œì‹œí•˜ì„¸ìš”
2. í•„ìš”ì‹œ ì½”ë“œ ì˜ˆì œë¥¼ í¬í•¨í•˜ì„¸ìš”
3. ë‹¨ê³„ë³„ë¡œ ì„¤ëª…í•˜ì„¸ìš”
4. ì°¸ê³ í•œ ë¬¸ì„œë¥¼ ëª…ì‹œí•˜ì„¸ìš”

ë‹µë³€:"""
```

### ë°©ì‹ C: ë©”íƒ€ë°ì´í„° í¬í•¨ ë²„ì „

```python
def metadata_rag_prompt(results: list, question: str) -> str:
    # ë¬¸ì„œì— ë©”íƒ€ë°ì´í„° í¬í•¨
    context_parts = []
    for i, result in enumerate(results, 1):
        title = result['metadata'].get('title', 'ì œëª© ì—†ìŒ')
        author = result['metadata'].get('author', 'ì‘ì„±ì ë¯¸ìƒ')
        date = result['metadata'].get('date', 'ë‚ ì§œ ë¯¸ìƒ')
        content = result['content']
        
        context_parts.append(f"""
[ë¬¸ì„œ {i}]
ì œëª©: {title}
ì‘ì„±ì: {author}
ë‚ ì§œ: {date}

ë‚´ìš©:
{content}
        """)
    
    context = "\n\n".join(context_parts)
    
    return f"""
ë‹¤ìŒ ë¬¸ì„œë“¤ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”:

{context}

ì§ˆë¬¸: {question}

ë‹µë³€:"""
```

---

## ğŸ”— ë‹¤ì–‘í•œ ì—°ê²° íŒ¨í„´

### íŒ¨í„´ 1: ê¸°ë³¸ RAG (ë‹¨ìˆœ ì—°ê²°)

```
ì§ˆë¬¸ â†’ ê²€ìƒ‰ â†’ ì»¨í…ìŠ¤íŠ¸ â†’ LLM â†’ ë‹µë³€
```

```python
def basic_rag(question):
    # 1. ê²€ìƒ‰
    docs = vector_search(question)
    
    # 2. ì»¨í…ìŠ¤íŠ¸ ìƒì„±
    context = "\n".join([d['content'] for d in docs])
    
    # 3. LLM í˜¸ì¶œ
    prompt = f"ë¬¸ì„œ: {context}\nì§ˆë¬¸: {question}"
    answer = llm.generate(prompt)
    
    return answer
```

### íŒ¨í„´ 2: í•„í„°ë§ RAG

```
ì§ˆë¬¸ â†’ ì˜ë„ íŒŒì•… â†’ í•„í„°ë§ ê²€ìƒ‰ â†’ ì»¨í…ìŠ¤íŠ¸ â†’ LLM â†’ ë‹µë³€
```

```python
def filtered_rag(question):
    # 1. ì§ˆë¬¸ ì˜ë„ íŒŒì•…
    category = classify_question(question)
    # "Python ì§ˆë¬¸" â†’ category="programming"
    
    # 2. í•„í„°ë§ ê²€ìƒ‰
    docs = vector_search(
        question,
        where={"category": category}  # í•„í„°!
    )
    
    # 3. ì»¨í…ìŠ¤íŠ¸ ìƒì„±
    context = "\n".join([d['content'] for d in docs])
    
    # 4. LLM í˜¸ì¶œ
    prompt = f"ë¬¸ì„œ: {context}\nì§ˆë¬¸: {question}"
    answer = llm.generate(prompt)
    
    return answer
```

### íŒ¨í„´ 3: ë‹¤ë‹¨ê³„ RAG (Re-ranking)

```
ì§ˆë¬¸ â†’ ê²€ìƒ‰ (10ê°œ) â†’ ì¬ìˆœìœ„ (3ê°œ) â†’ ì»¨í…ìŠ¤íŠ¸ â†’ LLM â†’ ë‹µë³€
```

```python
def reranking_rag(question):
    # 1. 1ì°¨ ê²€ìƒ‰ (ë§ì´)
    docs = vector_search(question, limit=10)
    
    # 2. ì¬ìˆœìœ„ (ì§ˆë¬¸ê³¼ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ê²ƒë§Œ)
    reranked = rerank(question, docs)
    top_docs = reranked[:3]
    
    # 3. ì»¨í…ìŠ¤íŠ¸ ìƒì„±
    context = "\n".join([d['content'] for d in top_docs])
    
    # 4. LLM í˜¸ì¶œ
    prompt = f"ë¬¸ì„œ: {context}\nì§ˆë¬¸: {question}"
    answer = llm.generate(prompt)
    
    return answer
```

### íŒ¨í„´ 4: í•˜ì´ë¸Œë¦¬ë“œ RAG (í‚¤ì›Œë“œ + ë²¡í„°)

```
ì§ˆë¬¸ â†’ í‚¤ì›Œë“œ ê²€ìƒ‰ + ë²¡í„° ê²€ìƒ‰ â†’ ê²°í•© â†’ ì»¨í…ìŠ¤íŠ¸ â†’ LLM â†’ ë‹µë³€
```

```python
def hybrid_rag(question):
    # 1-1. ë²¡í„° ê²€ìƒ‰
    vector_docs = vector_search(question, limit=5)
    
    # 1-2. í‚¤ì›Œë“œ ê²€ìƒ‰
    keywords = extract_keywords(question)
    keyword_docs = keyword_search(keywords, limit=5)
    
    # 2. ê²°í•© ë° ì¤‘ë³µ ì œê±°
    all_docs = merge_and_dedupe(vector_docs, keyword_docs)
    
    # 3. ì»¨í…ìŠ¤íŠ¸ ìƒì„±
    context = "\n".join([d['content'] for d in all_docs])
    
    # 4. LLM í˜¸ì¶œ
    prompt = f"ë¬¸ì„œ: {context}\nì§ˆë¬¸: {question}"
    answer = llm.generate(prompt)
    
    return answer
```

---

## ğŸ’¡ RAG vs LLM ë‹¨ë… ì‚¬ìš©

### LLMë§Œ ì‚¬ìš© (RAG ì—†ì´)

```python
def llm_only(question):
    """RAG ì—†ì´ LLMë§Œ ì‚¬ìš©"""
    prompt = f"ì§ˆë¬¸: {question}\në‹µë³€:"
    answer = llm.generate(prompt)
    return answer

# ë¬¸ì œì :
# âŒ LLMì´ ëª¨ë¥´ëŠ” ë‚´ìš©ì€ ë‹µë³€ ëª» í•¨
# âŒ ìµœì‹  ì •ë³´ ì—†ìŒ (í•™ìŠµ ë°ì´í„°ê¹Œì§€ë§Œ)
# âŒ íšŒì‚¬ ë‚´ë¶€ ì •ë³´ ëª¨ë¦„
# âŒ í™˜ê°(Hallucination) ê°€ëŠ¥
```

### RAG + LLM ì‚¬ìš©

```python
def rag_with_llm(question):
    """RAGë¡œ ë¬¸ì„œ ì°¾ê³  LLMì´ ë‹µë³€"""
    
    # 1. ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
    docs = vector_search(question)
    context = "\n".join([d['content'] for d in docs])
    
    # 2. ë¬¸ì„œ + ì§ˆë¬¸ì„ LLMì— ì „ë‹¬
    prompt = f"ë¬¸ì„œ: {context}\nì§ˆë¬¸: {question}"
    answer = llm.generate(prompt)
    
    return answer

# ì¥ì :
# âœ… LLMì´ ë¬¸ì„œ ê¸°ë°˜ìœ¼ë¡œ ì •í™•íˆ ë‹µë³€
# âœ… ìµœì‹  ì •ë³´ ë°˜ì˜ (ë¬¸ì„œë§Œ ì—…ë°ì´íŠ¸í•˜ë©´ ë¨)
# âœ… íšŒì‚¬ ë‚´ë¶€ ì •ë³´ í™œìš© ê°€ëŠ¥
# âœ… í™˜ê° í¬ê²Œ ê°ì†Œ (ë¬¸ì„œ ê¸°ë°˜)
```

### ë¹„êµ

```
ì§ˆë¬¸: "ìš°ë¦¬ íšŒì‚¬ 2024ë…„ 3ë¶„ê¸° ë§¤ì¶œì€?"

[LLMë§Œ ì‚¬ìš©]
LLM: "ì£„ì†¡í•©ë‹ˆë‹¤. íšŒì‚¬ì˜ ìµœì‹  ì¬ë¬´ ì •ë³´ëŠ” 
      ì œ í•™ìŠµ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤."
âŒ ë‹µë³€ ë¶ˆê°€

[RAG + LLM]
1. ChromaDB ê²€ìƒ‰ â†’ "2024 Q3 ì‹¤ì  ë³´ê³ ì„œ" ì°¾ìŒ
2. LLMì— ë³´ê³ ì„œ + ì§ˆë¬¸ ì „ë‹¬
3. LLM: "2024ë…„ 3ë¶„ê¸° ë§¤ì¶œì€ 1,250ì–µì›ì…ë‹ˆë‹¤.
        ì „ë…„ ëŒ€ë¹„ 15% ì¦ê°€í–ˆìŠµë‹ˆë‹¤."
âœ… ì •í™•í•œ ë‹µë³€!
```

---

## ğŸ¯ í•µì‹¬ ì •ë¦¬

### RAGì™€ LLMì˜ ì—­í•  ë¶„ë‹´

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RAG (Vector Search)                     â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ ì—­í• : ê´€ë ¨ ë¬¸ì„œ ì°¾ê¸°                     â”‚
â”‚ ì…ë ¥: ì‚¬ìš©ì ì§ˆë¬¸                        â”‚
â”‚ ì¶œë ¥: ê´€ë ¨ ë¬¸ì„œ 3-5ê°œ                    â”‚
â”‚ íŠ¹ì§•: ë¹ ë¥´ê³  ì •í™•í•œ ê²€ìƒ‰                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
        (ë¬¸ì„œ ì „ë‹¬)
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LLM (Language Model)                    â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ ì—­í• : ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ ìƒì„±                â”‚
â”‚ ì…ë ¥: ë¬¸ì„œ + ì§ˆë¬¸                        â”‚
â”‚ ì¶œë ¥: ìì—°ìŠ¤ëŸ¬ìš´ ë‹µë³€                    â”‚
â”‚ íŠ¹ì§•: ì´í•´ë ¥, ìƒì„±ë ¥                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ì—°ê²° í•µì‹¬ ì½”ë“œ

```python
# 1. ê²€ìƒ‰ (RAG)
docs = chromadb.search(question)  # ë¬¸ì„œ ì°¾ê¸°

# 2. ì—°ê²° (Augmentation)
context = combine(docs)  # ë¬¸ì„œë“¤ í•©ì¹˜ê¸°
prompt = f"{context}\n{question}"  # í”„ë¡¬í”„íŠ¸ ë§Œë“¤ê¸°

# 3. ìƒì„± (LLM)
answer = llm.generate(prompt)  # LLMì´ ë‹µë³€ ìƒì„±
```

---

**í•µì‹¬: RAGëŠ” ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì•„ì„œ LLMì—ê²Œ "ì°¸ê³  ìë£Œ"ë¡œ ì „ë‹¬í•©ë‹ˆë‹¤!** ğŸ“šâ†’ğŸ¤–
