#!/usr/bin/env python3
"""
ìœ ì‚¬ë„ ê²€ìƒ‰ ê¸°ë°˜ ë¬¸ì„œ ìš”ì•½ ì˜ˆì œ

ëŒ€ìš©ëŸ‰ ë¬¸ì„œì—ì„œ íŠ¹ì • ì£¼ì œì— ëŒ€í•œ ì •ë³´ë§Œ ì¶”ì¶œí•˜ì—¬ ìš”ì•½í•˜ëŠ” ì˜ˆì œì…ë‹ˆë‹¤.

ì‚¬ìš© ì‚¬ë¡€:
- 100í˜ì´ì§€ ë³´ê³ ì„œì—ì„œ "ì¬ë¬´ ì‹¤ì " ê´€ë ¨ ë‚´ìš©ë§Œ ì¶”ì¶œ
- ê¸´ ë…¼ë¬¸ì—ì„œ "ì‹¤í—˜ ë°©ë²•" ë¶€ë¶„ë§Œ ì°¾ê¸°
- ë²•ë¥  ë¬¸ì„œì—ì„œ íŠ¹ì • ì¡°í•­ ì°¾ê¸°
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent))

from rag.vector_store import ChromaVectorStore
import numpy as np
from typing import List
import time


class SimpleEmbeddingService:
    """ê°„ë‹¨í•œ ì„ë² ë”© ì„œë¹„ìŠ¤"""
    def __init__(self, dimension: int = 384):
        self.dimension = dimension
    
    def generate_embedding(self, text: str) -> List[float]:
        text_hash = hash(text) % (2**31)
        np.random.seed(text_hash)
        embedding = np.random.normal(0, 1, self.dimension)
        norm = np.linalg.norm(embedding)
        if norm > 0:
            embedding = embedding / norm
        return embedding.tolist()


def chunk_document(text: str, chunk_size: int = 200) -> List[str]:
    """ë¬¸ì„œë¥¼ ì‘ì€ ì²­í¬ë¡œ ë¶„í• """
    words = text.split()
    chunks = []
    
    for i in range(0, len(words), chunk_size):
        chunk = ' '.join(words[i:i + chunk_size])
        chunks.append(chunk)
    
    return chunks


def main():
    print("=" * 80)
    print("ğŸ“ ìœ ì‚¬ë„ ê²€ìƒ‰ ê¸°ë°˜ ë¬¸ì„œ ìš”ì•½ ì‹œìŠ¤í…œ")
    print("=" * 80)
    print()
    
    # 1. ì´ˆê¸°í™”
    print("[1ë‹¨ê³„] ì‹œìŠ¤í…œ ì´ˆê¸°í™”...")
    vector_store = ChromaVectorStore(
        persist_directory="./chroma-data",
        use_remote=False
    )
    embedding_service = SimpleEmbeddingService()
    collection_name = f"doc_summary_test_{int(time.time())}"
    vector_store.create_collection(collection_name, dimension=384)
    print("âœ… ì™„ë£Œ\n")
    
    # 2. ê°€ìƒì˜ ëŒ€ìš©ëŸ‰ ë³´ê³ ì„œ (ì‹¤ì œë¡œëŠ” ìˆ˜ë°± í˜ì´ì§€)
    print("[2ë‹¨ê³„] ëŒ€ìš©ëŸ‰ ë¬¸ì„œ ì¤€ë¹„...")
    print("-" * 80)
    
    # ê°€ìƒì˜ ê¸°ì—… ë¶„ê¸° ë³´ê³ ì„œ
    long_document = """
    2024ë…„ 3ë¶„ê¸° ì‹¤ì  ë³´ê³ ì„œ
    
    [ê²½ì˜ ì‹¤ì  ìš”ì•½]
    ë‹¹ì‚¬ëŠ” 2024ë…„ 3ë¶„ê¸°ì— ë§¤ì¶œ 1,250ì–µì›ì„ ë‹¬ì„±í•˜ì˜€ìœ¼ë©°, ì´ëŠ” ì „ë…„ ë™ê¸° ëŒ€ë¹„ 15% ì¦ê°€í•œ ìˆ˜ì¹˜ì…ë‹ˆë‹¤.
    ì˜ì—…ì´ìµì€ 180ì–µì›ìœ¼ë¡œ ì „ë…„ ëŒ€ë¹„ 20% ì¦ê°€í•˜ì˜€ìœ¼ë©°, ìˆœì´ìµì€ 140ì–µì›ì„ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤.
    ì£¼ìš” ì„±ì¥ ë™ë ¥ì€ ì‹ ì œí’ˆ ì¶œì‹œì™€ í•´ì™¸ ì‹œì¥ í™•ëŒ€ì— ìˆì—ˆìŠµë‹ˆë‹¤.
    
    [ì œí’ˆ ê°œë°œ í˜„í™©]
    ì—°êµ¬ê°œë°œíŒ€ì€ AI ê¸°ë°˜ ì¶”ì²œ ì‹œìŠ¤í…œ ê°œë°œì„ ì™„ë£Œí•˜ì˜€ìœ¼ë©°, ë² íƒ€ í…ŒìŠ¤íŠ¸ ì¤‘ì…ë‹ˆë‹¤.
    ìƒˆë¡œìš´ ëª¨ë°”ì¼ ì•±ì€ 10ë§Œ ë‹¤ìš´ë¡œë“œë¥¼ ëŒíŒŒí–ˆìœ¼ë©° ì‚¬ìš©ì ë§Œì¡±ë„ëŠ” 4.5ì ì…ë‹ˆë‹¤.
    ì°¨ì„¸ëŒ€ í”Œë«í¼ ê°œë°œì— 50ì–µì›ì„ íˆ¬ìí•˜ì˜€ìœ¼ë©°, 2025ë…„ 1ë¶„ê¸° ì¶œì‹œ ì˜ˆì •ì…ë‹ˆë‹¤.
    í–¥í›„ ë¨¸ì‹ ëŸ¬ë‹ê³¼ ìì—°ì–´ì²˜ë¦¬ ê¸°ìˆ ì„ í™œìš©í•œ ì‹ ê·œ ì„œë¹„ìŠ¤ë¥¼ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤.
    
    [ì‹œì¥ ë¶„ì„]
    êµ­ë‚´ ì‹œì¥ ì ìœ ìœ¨ì€ 23%ë¡œ ì—…ê³„ 2ìœ„ë¥¼ ìœ ì§€í•˜ê³  ìˆìŠµë‹ˆë‹¤.
    ê²½ìŸì‚¬ ëŒ€ë¹„ ê¸°ìˆ ë ¥ì—ì„œ ìš°ìœ„ë¥¼ ì í•˜ê³  ìˆìœ¼ë‚˜, ë§ˆì¼€íŒ… ì˜ˆì‚°ì€ ë¶€ì¡±í•œ ìƒí™©ì…ë‹ˆë‹¤.
    ê¸€ë¡œë²Œ ì‹œì¥ ì§„ì¶œì„ ìœ„í•´ ë™ë‚¨ì•„ì‹œì•„ 3ê°œêµ­ì— ì§€ì‚¬ë¥¼ ì„¤ë¦½í•  ì˜ˆì •ì…ë‹ˆë‹¤.
    ì‹œì¥ ì¡°ì‚¬ ê²°ê³¼, ê³ ê°ë“¤ì€ ê°€ê²©ë³´ë‹¤ í’ˆì§ˆê³¼ í¸ì˜ì„±ì„ ì¤‘ìš”í•˜ê²Œ ìƒê°í•˜ëŠ” ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤.
    
    [ì¬ë¬´ ìƒíƒœ]
    ì´ ìì‚°ì€ 5,200ì–µì›ì´ë©° ë¶€ì±„ë¹„ìœ¨ì€ 45%ë¡œ ì•ˆì •ì ì¸ ìˆ˜ì¤€ì…ë‹ˆë‹¤.
    í˜„ê¸ˆ ë° í˜„ê¸ˆì„± ìì‚°ì€ 1,100ì–µì›ìœ¼ë¡œ ì¶©ë¶„í•œ ìœ ë™ì„±ì„ í™•ë³´í•˜ê³  ìˆìŠµë‹ˆë‹¤.
    ì‹ ê·œ íˆ¬ìë¥¼ ìœ„í•´ 300ì–µì› ê·œëª¨ì˜ íšŒì‚¬ì±„ ë°œí–‰ì„ ê²€í†  ì¤‘ì…ë‹ˆë‹¤.
    ë°°ë‹¹ê¸ˆì€ ì£¼ë‹¹ 500ì›ìœ¼ë¡œ ì‘ë…„ ëŒ€ë¹„ 100ì› ì¦ê°€í•˜ì˜€ìŠµë‹ˆë‹¤.
    
    [ì¸ì‚¬ ì¡°ì§]
    3ë¶„ê¸° ì‹ ê·œ ì±„ìš© ì¸ì›ì€ 120ëª…ì´ë©°, ì´ ì§ì› ìˆ˜ëŠ” 1,850ëª…ì…ë‹ˆë‹¤.
    í‰ê·  ê·¼ì†ì—°ìˆ˜ëŠ” 5.2ë…„ì´ë©°, ì´ì§ë¥ ì€ 8%ë¡œ ì—…ê³„ í‰ê· ë³´ë‹¤ ë‚®ìŠµë‹ˆë‹¤.
    ì§ì› êµìœ¡ì— 20ì–µì›ì„ íˆ¬ìí•˜ì˜€ìœ¼ë©°, ë¦¬ë”ì‹­ í”„ë¡œê·¸ë¨ì„ ê°•í™”í–ˆìŠµë‹ˆë‹¤.
    ì¬íƒê·¼ë¬´ì™€ ìœ ì—°ê·¼ë¬´ì œë¥¼ í™•ëŒ€í•˜ì—¬ ì§ì› ë§Œì¡±ë„ê°€ í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤.
    
    [ë¦¬ìŠ¤í¬ ê´€ë¦¬]
    í™˜ìœ¨ ë³€ë™ì— ëŒ€ë¹„í•˜ì—¬ í—·ì§• ì „ëµì„ ìˆ˜ë¦½í•˜ì˜€ìŠµë‹ˆë‹¤.
    ì‚¬ì´ë²„ ë³´ì•ˆ ì‹œìŠ¤í…œì„ ê°•í™”í•˜ê³  ê°œì¸ì •ë³´ ë³´í˜¸ ì¡°ì¹˜ë¥¼ ê°•í™”í–ˆìŠµë‹ˆë‹¤.
    ê³µê¸‰ë§ ë‹¤ë³€í™”ë¥¼ í†µí•´ ì›ìì¬ ìˆ˜ê¸‰ ë¦¬ìŠ¤í¬ë¥¼ ìµœì†Œí™”í•˜ê³  ìˆìŠµë‹ˆë‹¤.
    ê·œì œ ë³€í™”ì— ëŒ€ì‘í•˜ê¸° ìœ„í•´ ë²•ë¬´íŒ€ì„ í™•ëŒ€ ê°œí¸í•˜ì˜€ìŠµë‹ˆë‹¤.
    
    [í–¥í›„ ì „ë§]
    4ë¶„ê¸°ì—ëŠ” ì—°ë§ ì‹œì¦Œ íš¨ê³¼ë¡œ ë§¤ì¶œ 1,400ì–µì›ì„ ëª©í‘œë¡œ í•˜ê³  ìˆìŠµë‹ˆë‹¤.
    2025ë…„ì—ëŠ” ì‹ ì‚¬ì—… ì§„ì¶œê³¼ M&Aë¥¼ í†µí•´ ì„±ì¥ì„ ê°€ì†í™”í•  ê³„íšì…ë‹ˆë‹¤.
    ë””ì§€í„¸ ì „í™˜ê³¼ AI ê¸°ìˆ  ë„ì…ìœ¼ë¡œ ìš´ì˜ íš¨ìœ¨ì„±ì„ 20% ê°œì„ í•  ì˜ˆì •ì…ë‹ˆë‹¤.
    ì§€ì†ê°€ëŠ¥ê²½ì˜ì„ ê°•í™”í•˜ê³  ESG í‰ê°€ ë“±ê¸‰ì„ ìƒí–¥ ì¡°ì •í•˜ëŠ” ê²ƒì´ ëª©í‘œì…ë‹ˆë‹¤.
    """
    
    print(f"ë¬¸ì„œ ê¸¸ì´: {len(long_document)}ì")
    print(f"ë¬¸ì„œ ë¯¸ë¦¬ë³´ê¸°:\n{long_document[:200]}...\n")
    
    # 3. ë¬¸ì„œë¥¼ ì‘ì€ ì²­í¬ë¡œ ë¶„í• 
    print("[3ë‹¨ê³„] ë¬¸ì„œë¥¼ ì²­í¬ë¡œ ë¶„í• ...")
    chunks = chunk_document(long_document, chunk_size=50)
    print(f"âœ… {len(chunks)}ê°œ ì²­í¬ë¡œ ë¶„í•  ì™„ë£Œ\n")
    
    # 4. ì²­í¬ë¥¼ ë²¡í„° DBì— ì €ì¥
    print("[4ë‹¨ê³„] ë²¡í„° DBì— ì €ì¥...")
    ids = [f"chunk_{i}" for i in range(len(chunks))]
    embeddings = [embedding_service.generate_embedding(chunk) for chunk in chunks]
    metadatas = [{"chunk_index": i} for i in range(len(chunks))]
    
    vector_store.add_vectors(
        collection_name=collection_name,
        ids=ids,
        embeddings=embeddings,
        metadatas=metadatas,
        documents=chunks
    )
    print(f"âœ… {len(chunks)}ê°œ ì²­í¬ ì €ì¥ ì™„ë£Œ\n")
    
    # 5. íŠ¹ì • ì£¼ì œì— ëŒ€í•œ ì •ë³´ë§Œ ì¶”ì¶œ
    print("=" * 80)
    print("[5ë‹¨ê³„] ì£¼ì œë³„ ì •ë³´ ì¶”ì¶œ í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    print()
    
    queries = [
        {
            "topic": "ì¬ë¬´ ì‹¤ì ",
            "query": "ë§¤ì¶œê³¼ ì˜ì—…ì´ìµ ì¬ë¬´ ì„±ê³¼",
            "description": "ì¬ë¬´ ê´€ë ¨ ìˆ˜ì¹˜ì™€ ì‹¤ì "
        },
        {
            "topic": "ì œí’ˆ ê°œë°œ",
            "query": "ì‹ ì œí’ˆ ê°œë°œ ì—°êµ¬ ê¸°ìˆ  í˜ì‹ ",
            "description": "R&Dì™€ ì œí’ˆ ê°œë°œ í˜„í™©"
        },
        {
            "topic": "ì¸ì‚¬ ì¡°ì§",
            "query": "ì§ì› ì±„ìš© ì¸ì‚¬ ì¡°ì§ ë¬¸í™”",
            "description": "ì¸ë ¥ ê´€ë¦¬ ë° ì¡°ì§ ë¬¸í™”"
        },
        {
            "topic": "í–¥í›„ ê³„íš",
            "query": "ë¯¸ë˜ ì „ë§ ê³„íš ëª©í‘œ ì „ëµ",
            "description": "í–¥í›„ ì‚¬ì—… ê³„íš ë° ì „ë§"
        },
    ]
    
    for i, test in enumerate(queries, 1):
        topic = test["topic"]
        query = test["query"]
        description = test["description"]
        
        print(f"\n{'='*80}")
        print(f"ğŸ” ì£¼ì œ {i}: {topic}")
        print(f"   ì„¤ëª…: {description}")
        print(f"   ê²€ìƒ‰ì–´: {query}")
        print('-' * 80)
        
        # ìœ ì‚¬ë„ ê²€ìƒ‰
        query_embedding = embedding_service.generate_embedding(query)
        results = vector_store.search_vectors(
            collection_name=collection_name,
            query_embedding=query_embedding,
            limit=3  # ìƒìœ„ 3ê°œ ê´€ë ¨ ì²­í¬ë§Œ
        )
        
        print(f"\nğŸ“„ ê´€ë ¨ ë‚´ìš© ({len(results)}ê°œ ì²­í¬):\n")
        
        # ìš”ì•½ ìƒì„± (ê´€ë ¨ ì²­í¬ë“¤ì„ í•©ì¹¨)
        summary_parts = []
        for j, result in enumerate(results, 1):
            similarity = result['similarity_score']
            content = result['content'].strip()
            
            print(f"[ì²­í¬ {j}] ìœ ì‚¬ë„: {similarity:.4f}")
            print(f"{content}\n")
            
            if similarity > 0.5:  # ìœ ì‚¬ë„ê°€ ë†’ì€ ê²ƒë§Œ ìš”ì•½ì— í¬í•¨
                summary_parts.append(content)
        
        # ìš”ì•½ë³¸
        if summary_parts:
            summary = " ".join(summary_parts)
            print(f"ğŸ’¡ {topic} ìš”ì•½:")
            print(f"   {summary[:300]}...")
    
    # 6. ì •ë¦¬
    print("\n" + "=" * 80)
    print("[6ë‹¨ê³„] ì •ë¦¬")
    print("=" * 80)
    
    response = input(f"\ní…ŒìŠ¤íŠ¸ ì»¬ë ‰ì…˜ì„ ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ")
    if response.lower() == 'y':
        vector_store.delete_collection(collection_name)
        print(f"âœ… ì»¬ë ‰ì…˜ ì‚­ì œ ì™„ë£Œ")
    else:
        print(f"â„¹ï¸  ì»¬ë ‰ì…˜ ìœ ì§€: {collection_name}")
    
    print("\n" + "=" * 80)
    print("ğŸ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("=" * 80)
    print()
    
    print("ğŸ“Š í™œìš© ì‚¬ë¡€:")
    print("-" * 80)
    print("âœ… ëŒ€ìš©ëŸ‰ ë³´ê³ ì„œì—ì„œ íŠ¹ì • ì£¼ì œë§Œ ì¶”ì¶œ")
    print("âœ… ê¸´ ë¬¸ì„œë¥¼ ì£¼ì œë³„ë¡œ ìë™ ë¶„ë¥˜")
    print("âœ… ê´€ë ¨ ì •ë³´ë§Œ ëª¨ì•„ì„œ ìš”ì•½ ìƒì„±")
    print("âœ… í‚¤ì›Œë“œ ì—†ì´ë„ ì˜ë¯¸ì ìœ¼ë¡œ ê´€ë ¨ëœ ë‚´ìš© ì°¾ê¸°")
    print()
    print("ğŸ’¡ ì‹¤ì œ í™œìš©:")
    print("   - ë²•ë¥  ë¬¸ì„œì—ì„œ íŠ¹ì • ì¡°í•­ ì°¾ê¸°")
    print("   - ë…¼ë¬¸ì—ì„œ ì‹¤í—˜ ë°©ë²•ë¡ ë§Œ ì¶”ì¶œ")
    print("   - ê³ ê° ë¦¬ë·°ì—ì„œ íŠ¹ì • ê¸°ëŠ¥ ê´€ë ¨ í”¼ë“œë°± ìˆ˜ì§‘")
    print("   - ë‰´ìŠ¤ ì•„ì¹´ì´ë¸Œì—ì„œ íŠ¹ì • ì‚¬ê±´ ê´€ë ¨ ê¸°ì‚¬ ì°¾ê¸°")
    print()


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâŒ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\n\nâŒ ì—ëŸ¬ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
