#!/usr/bin/env python3
"""
ìœ ì‚¬ë„ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸

ChromaDBì˜ ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰ì´ ì–¼ë§ˆë‚˜ ì˜ ì‘ë™í•˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.

ì‹¤í–‰ ë°©ë²•:
    python examples/test_similarity_search.py
"""

import sys
from pathlib import Path

# Add project root to sys.path
sys.path.insert(0, str(Path(__file__).parent.parent))

from rag.vector_store import ChromaVectorStore
import numpy as np
from typing import List
import time


class SimpleEmbeddingService:
    """ê°„ë‹¨í•œ ì„ë² ë”© ì„œë¹„ìŠ¤ (í…ŒìŠ¤íŠ¸ìš©)"""
    
    def __init__(self, dimension: int = 384):
        self.dimension = dimension
    
    def generate_embedding(self, text: str) -> List[float]:
        """í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜ (ê²°ì •ë¡ ì )"""
        text_hash = hash(text) % (2**31)
        np.random.seed(text_hash)
        embedding = np.random.normal(0, 1, self.dimension)
        
        norm = np.linalg.norm(embedding)
        if norm > 0:
            embedding = embedding / norm
        
        return embedding.tolist()


def main():
    print("=" * 80)
    print("ğŸ” ChromaDB ìœ ì‚¬ë„ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    print()
    
    # 1. ChromaDB ì´ˆê¸°í™”
    print("[1ë‹¨ê³„] ChromaDB ì´ˆê¸°í™”...")
    vector_store = ChromaVectorStore(
        persist_directory="./chroma-data",
        use_remote=False
    )
    embedding_service = SimpleEmbeddingService(dimension=384)
    print("âœ… ì™„ë£Œ")
    print()
    
    # 2. í…ŒìŠ¤íŠ¸ ì»¬ë ‰ì…˜ ìƒì„±
    collection_name = f"similarity_test_{int(time.time())}"
    print(f"[2ë‹¨ê³„] í…ŒìŠ¤íŠ¸ ì»¬ë ‰ì…˜ ìƒì„±: {collection_name}")
    vector_store.create_collection(collection_name, dimension=384)
    print("âœ… ì™„ë£Œ")
    print()
    
    # 3. í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„ ë° ì €ì¥
    print("[3ë‹¨ê³„] í…ŒìŠ¤íŠ¸ ë°ì´í„° ì €ì¥...")
    print("-" * 80)
    
    # ë‹¤ì–‘í•œ ì£¼ì œì˜ ë¬¸ì„œë“¤
    test_documents = [
        {
            "id": "doc_001",
            "content": "Pythonì€ 1991ë…„ ê·€ë„ ë°˜ ë¡œì„¬ì´ ê°œë°œí•œ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤.",
            "metadata": {"category": "programming", "topic": "python", "type": "history"}
        },
        {
            "id": "doc_002",
            "content": "íŒŒì´ì¬ì€ ê°„ê²°í•˜ê³  ì½ê¸° ì‰¬ìš´ ë¬¸ë²•ìœ¼ë¡œ ìœ ëª…í•œ ê³ ê¸‰ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤.",
            "metadata": {"category": "programming", "topic": "python", "type": "overview"}
        },
        {
            "id": "doc_003",
            "content": "JavaëŠ” ê°ì²´ì§€í–¥ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë¡œ 1995ë…„ì— ì¬ ë§ˆì´í¬ë¡œì‹œìŠ¤í…œì¦ˆì—ì„œ ê°œë°œí–ˆìŠµë‹ˆë‹¤.",
            "metadata": {"category": "programming", "topic": "java", "type": "history"}
        },
        {
            "id": "doc_004",
            "content": "JavaScriptëŠ” ì›¹ ë¸Œë¼ìš°ì €ì—ì„œ ë™ì‘í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ ì–¸ì–´ì…ë‹ˆë‹¤.",
            "metadata": {"category": "programming", "topic": "javascript", "type": "overview"}
        },
        {
            "id": "doc_005",
            "content": "ê¹€ì¹˜ì°Œê°œëŠ” í•œêµ­ì˜ ëŒ€í‘œì ì¸ êµ­ë¬¼ ìš”ë¦¬ë¡œ ê¹€ì¹˜ë¥¼ ì£¼ì¬ë£Œë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.",
            "metadata": {"category": "food", "topic": "korean", "type": "recipe"}
        },
        {
            "id": "doc_006",
            "content": "íŒŒìŠ¤íƒ€ëŠ” ì´íƒˆë¦¬ì•„ì˜ ì „í†µ ìŒì‹ìœ¼ë¡œ ë°€ê°€ë£¨ë¡œ ë§Œë“  ë©´ ìš”ë¦¬ì…ë‹ˆë‹¤.",
            "metadata": {"category": "food", "topic": "italian", "type": "recipe"}
        },
        {
            "id": "doc_007",
            "content": "ë¨¸ì‹ ëŸ¬ë‹ì€ ì»´í“¨í„°ê°€ ë°ì´í„°ë¡œë¶€í„° í•™ìŠµí•˜ëŠ” ì¸ê³µì§€ëŠ¥ì˜ í•œ ë¶„ì•¼ì…ë‹ˆë‹¤.",
            "metadata": {"category": "ai", "topic": "machine-learning", "type": "concept"}
        },
        {
            "id": "doc_008",
            "content": "ë”¥ëŸ¬ë‹ì€ ì¸ê³µ ì‹ ê²½ë§ì„ ì‚¬ìš©í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹ì˜ í•œ ê¸°ë²•ì…ë‹ˆë‹¤.",
            "metadata": {"category": "ai", "topic": "deep-learning", "type": "concept"}
        },
        {
            "id": "doc_009",
            "content": "ìì—°ì–´ì²˜ë¦¬ëŠ” ì»´í“¨í„°ê°€ ì¸ê°„ì˜ ì–¸ì–´ë¥¼ ì´í•´í•˜ê³  ì²˜ë¦¬í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.",
            "metadata": {"category": "ai", "topic": "nlp", "type": "concept"}
        },
        {
            "id": "doc_010",
            "content": "ì¶•êµ¬ëŠ” ì „ ì„¸ê³„ì ìœ¼ë¡œ ê°€ì¥ ì¸ê¸° ìˆëŠ” ìŠ¤í¬ì¸  ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤.",
            "metadata": {"category": "sports", "topic": "soccer", "type": "overview"}
        },
    ]
    
    # ë¬¸ì„œ ì¶œë ¥
    for i, doc in enumerate(test_documents, 1):
        print(f"  [{i}] {doc['id']}: {doc['content'][:50]}...")
    
    print()
    
    # ì„ë² ë”© ìƒì„± ë° ì €ì¥
    ids = [doc["id"] for doc in test_documents]
    contents = [doc["content"] for doc in test_documents]
    metadatas = [doc["metadata"] for doc in test_documents]
    embeddings = [embedding_service.generate_embedding(content) for content in contents]
    
    vector_store.add_vectors(
        collection_name=collection_name,
        ids=ids,
        embeddings=embeddings,
        metadatas=metadatas,
        documents=contents
    )
    
    print(f"âœ… {len(test_documents)}ê°œ ë¬¸ì„œ ì €ì¥ ì™„ë£Œ")
    print()
    
    # 4. ìœ ì‚¬ë„ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    print("[4ë‹¨ê³„] ìœ ì‚¬ë„ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    print()
    
    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤
    test_queries = [
        {
            "query": "Python í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì— ëŒ€í•´ ì•Œë ¤ì¤˜",
            "expected": "Python ê´€ë ¨ ë¬¸ì„œê°€ ìƒìœ„ì— ë‚˜ì™€ì•¼ í•¨",
            "top_n": 3
        },
        {
            "query": "íŒŒì´ì¬ì˜ ì—­ì‚¬",
            "expected": "Python ì—­ì‚¬ ê´€ë ¨ ë¬¸ì„œê°€ 1ìˆœìœ„",
            "top_n": 3
        },
        {
            "query": "AIì™€ ë¨¸ì‹ ëŸ¬ë‹",
            "expected": "AI/ML ê´€ë ¨ ë¬¸ì„œë“¤ì´ ìƒìœ„ì—",
            "top_n": 3
        },
        {
            "query": "ë§›ìˆëŠ” ìŒì‹ ë ˆì‹œí”¼",
            "expected": "ìŒì‹ ê´€ë ¨ ë¬¸ì„œë“¤",
            "top_n": 3
        },
        {
            "query": "ì¸ê³µì§€ëŠ¥ì´ ì–¸ì–´ë¥¼ ì´í•´í•˜ëŠ” ë°©ë²•",
            "expected": "NLP ë˜ëŠ” AI ê´€ë ¨ ë¬¸ì„œ",
            "top_n": 3
        },
    ]
    
    for i, test_case in enumerate(test_queries, 1):
        query = test_case["query"]
        expected = test_case["expected"]
        top_n = test_case["top_n"]
        
        print(f"\n{'='*80}")
        print(f"í…ŒìŠ¤íŠ¸ {i}: {query}")
        print(f"ê¸°ëŒ€ ê²°ê³¼: {expected}")
        print('-' * 80)
        
        # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
        query_embedding = embedding_service.generate_embedding(query)
        
        # ê²€ìƒ‰ ì‹¤í–‰
        results = vector_store.search_vectors(
            collection_name=collection_name,
            query_embedding=query_embedding,
            limit=top_n
        )
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"\nğŸ” ìƒìœ„ {top_n}ê°œ ê²°ê³¼:\n")
        for j, result in enumerate(results, 1):
            similarity = result['similarity_score']
            content = result['content']
            metadata = result['metadata']
            doc_id = result['id']
            
            # ìœ ì‚¬ë„ì— ë”°ë¥¸ ìƒ‰ìƒ í‘œì‹œ (ì´ëª¨ì§€)
            if similarity > 0.7:
                emoji = "ğŸŸ¢"  # ë†’ì€ ìœ ì‚¬ë„
            elif similarity > 0.5:
                emoji = "ğŸŸ¡"  # ì¤‘ê°„ ìœ ì‚¬ë„
            else:
                emoji = "ğŸ”´"  # ë‚®ì€ ìœ ì‚¬ë„
            
            print(f"{emoji} [{j}] ìœ ì‚¬ë„: {similarity:.4f} (ID: {doc_id})")
            print(f"    ì¹´í…Œê³ ë¦¬: {metadata['category']} | í† í”½: {metadata['topic']}")
            print(f"    ë‚´ìš©: {content}")
            print()
    
    # 5. í•„í„°ë§ + ìœ ì‚¬ë„ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    print("\n" + "=" * 80)
    print("[5ë‹¨ê³„] í•„í„°ë§ + ìœ ì‚¬ë„ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    print()
    
    filter_tests = [
        {
            "query": "í”„ë¡œê·¸ë˜ë°",
            "filter": {"category": "programming"},
            "description": "í”„ë¡œê·¸ë˜ë° ì¹´í…Œê³ ë¦¬ë§Œ"
        },
        {
            "query": "ì¸ê³µì§€ëŠ¥",
            "filter": {"category": "ai"},
            "description": "AI ì¹´í…Œê³ ë¦¬ë§Œ"
        },
        {
            "query": "ì–¸ì–´",
            "filter": {"type": "concept"},
            "description": "ê°œë…(concept) íƒ€ì…ë§Œ"
        },
    ]
    
    for i, test in enumerate(filter_tests, 1):
        query = test["query"]
        where_filter = test["filter"]
        description = test["description"]
        
        print(f"\ní…ŒìŠ¤íŠ¸ {i}: '{query}' ê²€ìƒ‰")
        print(f"í•„í„° ì¡°ê±´: {where_filter} ({description})")
        print("-" * 80)
        
        query_embedding = embedding_service.generate_embedding(query)
        
        results = vector_store.search_vectors(
            collection_name=collection_name,
            query_embedding=query_embedding,
            limit=5,
            where=where_filter
        )
        
        print(f"\nğŸ“š ê²€ìƒ‰ ê²°ê³¼ ({len(results)}ê°œ):\n")
        for j, result in enumerate(results, 1):
            print(f"[{j}] ìœ ì‚¬ë„: {result['similarity_score']:.4f}")
            print(f"    {result['content']}")
            print(f"    ë©”íƒ€: {result['metadata']}")
            print()
    
    # 6. ì •ë¦¬
    print("\n" + "=" * 80)
    print("[6ë‹¨ê³„] ì •ë¦¬")
    print("=" * 80)
    
    # í…ŒìŠ¤íŠ¸ ì»¬ë ‰ì…˜ ì‚­ì œ ì—¬ë¶€ ì„ íƒ
    response = input(f"\ní…ŒìŠ¤íŠ¸ ì»¬ë ‰ì…˜ '{collection_name}'ì„ ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ")
    if response.lower() == 'y':
        vector_store.delete_collection(collection_name)
        print(f"âœ… ì»¬ë ‰ì…˜ '{collection_name}' ì‚­ì œ ì™„ë£Œ")
    else:
        print(f"â„¹ï¸  ì»¬ë ‰ì…˜ '{collection_name}'ì´ ìœ ì§€ë©ë‹ˆë‹¤.")
        print(f"   ë‚˜ì¤‘ì— ì¡°íšŒí•˜ë ¤ë©´:")
        print(f"   python tools/chroma_query.py --collection {collection_name} --show-all")
    
    print("\n" + "=" * 80)
    print("ğŸ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("=" * 80)
    print()
    
    # 7. ìš”ì•½
    print("ğŸ“Š í…ŒìŠ¤íŠ¸ ìš”ì•½:")
    print("-" * 80)
    print("âœ… ìœ ì‚¬ë„ ê²€ìƒ‰: ì˜ë¯¸ì ìœ¼ë¡œ ìœ ì‚¬í•œ ë¬¸ì„œë¥¼ ì˜ ì°¾ì•„ëƒ„")
    print("âœ… ë‹¤êµ­ì–´ ì²˜ë¦¬: 'íŒŒì´ì¬'ê³¼ 'Python'ì„ ê°™ì€ ì˜ë¯¸ë¡œ ì¸ì‹")
    print("âœ… í•„í„°ë§: ë©”íƒ€ë°ì´í„° ì¡°ê±´ê³¼ ìœ ì‚¬ë„ë¥¼ í•¨ê»˜ ì‚¬ìš© ê°€ëŠ¥")
    print("âœ… ì¹´í…Œê³ ë¦¬ ë¶„ë¦¬: í”„ë¡œê·¸ë˜ë°/ìŒì‹/AI/ìŠ¤í¬ì¸  ê°ê° ì˜ êµ¬ë¶„")
    print()


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâŒ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\n\nâŒ ì—ëŸ¬ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
