#!/usr/bin/env python3
"""
ÌååÏùº Í∏∞Î∞ò Î¨∏ÏÑú ÏûÑÌè¨Ìä∏ Ïú†Ìã∏Î¶¨Ìã∞

ÌååÏùº Ìè¨Îß∑:
documents = [
  {
    "id": "doc_001",  # Optional: ÏÉùÎûµ Ïãú ÏûêÎèô ÏÉùÏÑ±
    "document": "Î¨∏ÏÑú ÎÇ¥Ïö©...",
    "metadata": {
      "key": "value"
    }
  },
  ...
]
"""

import sys
import os
import uuid
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime


class DocumentImporter:
    """Î¨∏ÏÑú ÏûÑÌè¨Ìä∏ Ïú†Ìã∏Î¶¨Ìã∞"""
    
    @staticmethod
    def load_documents_from_file(file_path: str) -> List[Dict[str, Any]]:
        """
        Python ÌååÏùºÏóêÏÑú documents Î≥ÄÏàòÎ•º Î°úÎìú
        
        Args:
            file_path: ÌååÏùº Í≤ΩÎ°ú
            
        Returns:
            Î¨∏ÏÑú Î¶¨Ïä§Ìä∏
            
        Raises:
            FileNotFoundError: ÌååÏùºÏù¥ ÏóÜÏùå
            ValueError: ÌååÏùº ÌòïÏãù Ïò§Î•ò
        """
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"File not found: {file_path}")
        
        # ÌååÏùº ÏùΩÍ∏∞
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # Python ÏΩîÎìú Ïã§ÌñâÌïòÏó¨ documents Î≥ÄÏàò Ï∂îÏ∂ú
        local_vars = {}
        try:
            exec(content, {}, local_vars)
        except Exception as e:
            raise ValueError(f"Failed to parse file: {e}")
        
        # documents Î≥ÄÏàò ÌôïÏù∏
        if 'documents' not in local_vars:
            raise ValueError("File must contain 'documents' variable")
        
        documents = local_vars['documents']
        
        if not isinstance(documents, list):
            raise ValueError("'documents' must be a list")
        
        return documents
    
    @staticmethod
    def validate_document(doc: Dict[str, Any], index: int) -> None:
        """
        Î¨∏ÏÑú ÌòïÏãù Í≤ÄÏ¶ù
        
        Args:
            doc: Î¨∏ÏÑú ÎîïÏÖîÎÑàÎ¶¨
            index: Î¨∏ÏÑú Ïù∏Îç±Ïä§ (ÏóêÎü¨ Î©îÏãúÏßÄÏö©)
            
        Raises:
            ValueError: ÌòïÏãù Ïò§Î•ò
        """
        if not isinstance(doc, dict):
            raise ValueError(f"Document at index {index} must be a dictionary")
        
        # document ÌïÑÎìú ÌïÑÏàò
        if 'document' not in doc:
            raise ValueError(f"Document at index {index} missing 'document' field")
        
        # documentÎäî Î¨∏ÏûêÏó¥Ïù¥Ïñ¥Ïïº Ìï®
        if not isinstance(doc['document'], str):
            raise ValueError(f"Document at index {index}: 'document' must be a string")
        
        # metadataÎäî ÎîïÏÖîÎÑàÎ¶¨Ïó¨Ïïº Ìï® (ÏûàÎäî Í≤ΩÏö∞)
        if 'metadata' in doc and not isinstance(doc['metadata'], dict):
            raise ValueError(f"Document at index {index}: 'metadata' must be a dictionary")
    
    @staticmethod
    def prepare_documents(
        documents: List[Dict[str, Any]], 
        auto_generate_id: bool = True,
        add_import_metadata: bool = True
    ) -> Tuple[List[str], List[str], List[Dict[str, Any]]]:
        """
        ChromaDB ÌòïÏãùÏúºÎ°ú Î¨∏ÏÑú Ï§ÄÎπÑ
        
        Args:
            documents: ÏõêÎ≥∏ Î¨∏ÏÑú Î¶¨Ïä§Ìä∏
            auto_generate_id: ID ÏûêÎèô ÏÉùÏÑ± Ïó¨Î∂Ä (IDÍ∞Ä ÏóÜÎäî Í≤ΩÏö∞)
            add_import_metadata: ÏûÑÌè¨Ìä∏ Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ Ï∂îÍ∞Ä Ïó¨Î∂Ä
            
        Returns:
            (ids, documents, metadatas) ÌäúÌîå
            
        Raises:
            ValueError: ID Ï§ëÎ≥µ ÎòêÎäî ÌòïÏãù Ïò§Î•ò
        """
        ids = []
        docs = []
        metadatas = []
        
        seen_ids = set()
        
        for i, doc in enumerate(documents):
            # Í≤ÄÏ¶ù
            DocumentImporter.validate_document(doc, i)
            
            # ID Ï≤òÎ¶¨
            doc_id = doc.get('id')
            
            if doc_id is None:
                if auto_generate_id:
                    # ID ÏûêÎèô ÏÉùÏÑ±
                    doc_id = f"doc_{uuid.uuid4().hex[:12]}"
                else:
                    raise ValueError(f"Document at index {i} missing 'id' field (auto_generate_id=False)")
            
            # ID ÌÉÄÏûÖ ÌôïÏù∏
            if not isinstance(doc_id, str):
                raise ValueError(f"Document at index {i}: 'id' must be a string")
            
            # ID Ï§ëÎ≥µ ÌôïÏù∏
            if doc_id in seen_ids:
                raise ValueError(f"Duplicate document ID: {doc_id}")
            
            seen_ids.add(doc_id)
            ids.append(doc_id)
            
            # Î¨∏ÏÑú ÎÇ¥Ïö©
            docs.append(doc['document'])
            
            # Î©îÌÉÄÎç∞Ïù¥ÌÑ∞
            metadata = doc.get('metadata', {}).copy()
            
            # ÏûÑÌè¨Ìä∏ Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ Ï∂îÍ∞Ä
            if add_import_metadata:
                metadata['imported_at'] = str(datetime.now())
                metadata['import_source'] = 'file_import'
            
            metadatas.append(metadata)
        
        return ids, docs, metadatas
    
    @staticmethod
    def import_to_collection(
        collection,
        file_path: str,
        auto_generate_id: bool = True,
        batch_size: int = 100,
        verbose: bool = True
    ) -> Dict[str, Any]:
        """
        ÌååÏùºÏóêÏÑú Î¨∏ÏÑúÎ•º ÏùΩÏñ¥ ÏΩúÎ†âÏÖòÏóê ÏûÑÌè¨Ìä∏
        
        Args:
            collection: ChromaDB ÏΩúÎ†âÏÖò
            file_path: ÌååÏùº Í≤ΩÎ°ú
            auto_generate_id: ID ÏûêÎèô ÏÉùÏÑ± Ïó¨Î∂Ä
            batch_size: Î∞∞Ïπò ÌÅ¨Í∏∞
            verbose: ÏßÑÌñâ ÏÉÅÌô© Ï∂úÎ†• Ïó¨Î∂Ä
            
        Returns:
            ÏûÑÌè¨Ìä∏ Í≤∞Í≥º ÌÜµÍ≥Ñ
        """
        if verbose:
            print(f"\nüìÇ Loading documents from: {file_path}")
        
        # ÌååÏùº Î°úÎìú
        try:
            documents = DocumentImporter.load_documents_from_file(file_path)
        except Exception as e:
            if verbose:
                print(f"‚ùå Error loading file: {e}")
            raise
        
        if verbose:
            print(f"‚úÖ Loaded {len(documents)} documents from file")
        
        # Î¨∏ÏÑú Ï§ÄÎπÑ
        try:
            ids, docs, metadatas = DocumentImporter.prepare_documents(
                documents, 
                auto_generate_id=auto_generate_id
            )
        except Exception as e:
            if verbose:
                print(f"‚ùå Error preparing documents: {e}")
            raise
        
        if verbose:
            print(f"‚úÖ Prepared {len(ids)} documents for import")
            
            # ID ÏÉùÏÑ± ÌÜµÍ≥Ñ
            auto_generated = sum(1 for doc in documents if doc.get('id') is None)
            if auto_generated > 0:
                print(f"   - Auto-generated IDs: {auto_generated}")
            if len(documents) - auto_generated > 0:
                print(f"   - Custom IDs: {len(documents) - auto_generated}")
        
        # Î∞∞ÏπòÎ°ú ÏûÑÌè¨Ìä∏
        total = len(ids)
        imported = 0
        errors = []
        
        if verbose:
            print(f"\nüì• Importing documents (batch_size={batch_size})...")
        
        for i in range(0, total, batch_size):
            batch_end = min(i + batch_size, total)
            batch_ids = ids[i:batch_end]
            batch_docs = docs[i:batch_end]
            batch_metadatas = metadatas[i:batch_end]
            
            try:
                collection.add(
                    ids=batch_ids,
                    documents=batch_docs,
                    metadatas=batch_metadatas
                )
                imported += len(batch_ids)
                
                if verbose:
                    print(f"   Batch {i//batch_size + 1}: {len(batch_ids)} documents ‚úì")
                    
            except Exception as e:
                error_msg = f"Batch {i//batch_size + 1} failed: {e}"
                errors.append(error_msg)
                if verbose:
                    print(f"   Batch {i//batch_size + 1}: ‚úó {e}")
        
        # Í≤∞Í≥º
        result = {
            'total': total,
            'imported': imported,
            'failed': total - imported,
            'errors': errors
        }
        
        if verbose:
            print(f"\n{'='*60}")
            print(f"‚úÖ Import completed")
            print(f"   Total: {result['total']}")
            print(f"   Imported: {result['imported']}")
            if result['failed'] > 0:
                print(f"   Failed: {result['failed']}")
                for error in errors:
                    print(f"      - {error}")
            print(f"{'='*60}\n")
        
        return result
    
    @staticmethod
    def preview_file(file_path: str, max_docs: int = 5) -> None:
        """
        ÌååÏùº ÎÇ¥Ïö© ÎØ∏Î¶¨Î≥¥Í∏∞
        
        Args:
            file_path: ÌååÏùº Í≤ΩÎ°ú
            max_docs: ÏµúÎåÄ ÌëúÏãú Î¨∏ÏÑú Í∞úÏàò
        """
        print(f"\nüìÑ File Preview: {file_path}")
        print("="*60)
        
        try:
            documents = DocumentImporter.load_documents_from_file(file_path)
            
            print(f"Total documents: {len(documents)}\n")
            
            for i, doc in enumerate(documents[:max_docs]):
                print(f"Document {i+1}:")
                print(f"  ID: {doc.get('id', '(auto-generate)')}")
                
                content = doc.get('document', '')
                content_preview = content[:100] + "..." if len(content) > 100 else content
                print(f"  Content: {content_preview}")
                
                metadata = doc.get('metadata', {})
                print(f"  Metadata: {metadata}")
                print()
            
            if len(documents) > max_docs:
                print(f"... and {len(documents) - max_docs} more documents")
            
            print("="*60)
            
        except Exception as e:
            print(f"‚ùå Error: {e}")


def main():
    """ÌÖåÏä§Ìä∏ Î∞è CLI"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description="Document Import Utility",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Preview file
  python tools/file_import.py --preview sample_documents.py
  
  # Validate file format
  python tools/file_import.py --validate sample_documents.py
        """
    )
    
    parser.add_argument(
        'file',
        help='Document file path'
    )
    
    parser.add_argument(
        '--preview',
        action='store_true',
        help='Preview file contents'
    )
    
    parser.add_argument(
        '--validate',
        action='store_true',
        help='Validate file format'
    )
    
    parser.add_argument(
        '--max-docs',
        type=int,
        default=5,
        help='Maximum documents to preview (default: 5)'
    )
    
    args = parser.parse_args()
    
    if args.preview:
        DocumentImporter.preview_file(args.file, args.max_docs)
    elif args.validate:
        try:
            documents = DocumentImporter.load_documents_from_file(args.file)
            ids, docs, metadatas = DocumentImporter.prepare_documents(documents)
            print(f"‚úÖ File is valid")
            print(f"   Documents: {len(documents)}")
            print(f"   Auto-generated IDs: {sum(1 for doc in documents if doc.get('id') is None)}")
        except Exception as e:
            print(f"‚ùå Validation failed: {e}")
            sys.exit(1)
    else:
        # Í∏∞Î≥∏: preview
        DocumentImporter.preview_file(args.file, args.max_docs)


if __name__ == "__main__":
    main()
